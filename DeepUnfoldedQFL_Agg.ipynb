{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanikairoshi/QFL-with-DUN/blob/main/DeepUnfoldedQFL_Agg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzSBAZQyuhjz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Quantum Federated Learning with Deep Unfolding based Weights\n",
        "\n",
        "In this notebook provide the novel implementation of quantum federated learning which manage the client specific weights based on deep unfolding technique to enhance the benchmark federated settings and by then improve the performance of naive federated averaging. We currently, implement most widely used benchmark dataset and hope to enhance this version to implement with genomic data.\n",
        "\n",
        "01. Module 01 - Weight calculation on NN based Deep unfolding.\n",
        "02. Module 02 - Federated training process."
      ],
      "metadata": {
        "id": "i47EU48w31f4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 01: Required Dependancies**\n",
        "\n",
        "Before execute the code, require ensure that you have the necessary libraries installed. The following commands will help you install required libraries:\n",
        "\n",
        "The line from IPython.display import clear_output prevents dispalying unnessary output."
      ],
      "metadata": {
        "id": "iykXdYdVPW24"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iHP0mX7juiK1"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "#Install required Dependencies\n",
        "!pip install --upgrade seaborn\n",
        "!pip install --upgrade scikit-learn\n",
        "!pip install --upgrade matplotlib\n",
        "!pip install --upgrade pandas\n",
        "!pip install --upgrade qiskit\n",
        "!pip install qiskit_machine_learning\n",
        "\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.manifold import TSNE\n",
        "from qiskit import *\n",
        "from qiskit.utils import algorithm_globals\n",
        "from qiskit.circuit.library import ZFeatureMap, TwoLocal\n",
        "from qiskit.circuit.library import RealAmplitudes\n",
        "from qiskit_machine_learning.datasets import ad_hoc_data\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "#from qiskit_machine_learning.optimizers import SPSA\n",
        "from qiskit import BasicAer, execute\n",
        "from qiskit.algorithms.optimizers import SPSA\n",
        "from qiskit.algorithms.optimizers import COBYLA\n",
        "import time\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHB0VV75ZqNS"
      },
      "source": [
        "**Step 02: Load dataset, dimensionality reduction and extracting data and finalize with normalized structure.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMlVVPFZZ2cu"
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "algorithm_globals.random_seed = 3142\n",
        "np.random.seed(algorithm_globals.random_seed)\n",
        "\n",
        "# Define the feature map and variational form\n",
        "FEATURE_MAP = ZFeatureMap(feature_dimension=2, reps=2)\n",
        "VAR_FORM = TwoLocal(2, ['ry', 'rz'], 'cz', reps=2)\n",
        "\n",
        "#======================================\n",
        "#Loading Data\n",
        "image_size = 28 # width and length are equal\n",
        "data_path= \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "train_data = np.loadtxt(data_path + \"mnist_train.csv\", delimiter=\",\")\n",
        "test_data = np.loadtxt(data_path + \"mnist_test.csv\", delimiter=\",\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Cr22OM0tMnUd"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Dimensionality Reduction\n",
        "#Extracting features and labels from the dataset and truncating the dataset to 10,000 datapoints\n",
        "train_data_features = train_data[:10000, 1:]\n",
        "train_data_labels = train_data[:10000, :1].reshape(10000,)\n",
        "\n",
        "# Using SVD to reduce dimensions to 10\n",
        "tsvd = TruncatedSVD(n_components=10)\n",
        "X_SVD = tsvd.fit_transform(train_data_features)\n",
        "\n",
        "# Use t-SNE technique to reduce dimensions to 2\n",
        "np.random.seed(0)\n",
        "tsne = TSNE(n_components=2)\n",
        "train_data_features_reduced = tsne.fit_transform(X_SVD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qr9O20vY-zZL"
      },
      "outputs": [],
      "source": [
        "#Extracting and Normalizing Data\n",
        "zero_datapoints_array = [] #an array of the data points containing value 0\n",
        "one_datapoints_array = []# an array of the data points containing value 1\n",
        "for i in range(10000):\n",
        "    if train_data_labels[i] == 0:                   # extracting zeros\n",
        "        zero_datapoints_array.append(train_data_features_reduced[i])\n",
        "\n",
        "for i in range(10000):\n",
        "    if train_data_labels[i] == 1:                   # extracting ones\n",
        "        one_datapoints_array.append(train_data_features_reduced[i])\n",
        "\n",
        "zero_datapoints_array = np.array(zero_datapoints_array)\n",
        "one_datapoints_array = np.array(one_datapoints_array)\n",
        "\n",
        "def normalize(arr, max_val, n):\n",
        "    a = np.divide(arr, max_val)\n",
        "    return a + n\n",
        "zero_datapoints_normalized = normalize(zero_datapoints_array, 100, 1)\n",
        "one_datapoints_normalized = normalize(one_datapoints_array, 100, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkaBvENo_QKw"
      },
      "outputs": [],
      "source": [
        "#Split data into clients in federated setting\n",
        "# Assuming you have the data defined as per your initial code\n",
        "train_size = 200\n",
        "test_size = 10\n",
        "dp_size_zero = 5\n",
        "dp_size_one = 5\n",
        "\n",
        "zero_train = zero_datapoints_normalized[:train_size]\n",
        "one_train = one_datapoints_normalized[:train_size]\n",
        "\n",
        "zero_test = zero_datapoints_normalized[train_size + 1:train_size + test_size + 1]\n",
        "one_test = one_datapoints_normalized[train_size + 1:train_size + test_size + 1]\n",
        "\n",
        "training_input = {'A': zero_train, 'B': one_train}\n",
        "test_input = {'A': zero_test, 'B': one_test}\n",
        "\n",
        "datapoints = []\n",
        "dp_zero = zero_datapoints_normalized[train_size + test_size + 2:train_size + test_size + 2 + dp_size_zero]\n",
        "dp_one = one_datapoints_normalized[train_size + test_size + 2:train_size + test_size + 2 + dp_size_one]\n",
        "datapoints.append(np.concatenate((dp_zero, dp_one)))\n",
        "dp_y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "datapoints.append(dp_y)\n",
        "\n",
        "class_to_label = {'A': 0, 'B': 1}\n",
        "\n",
        "# Split data for 5 clients\n",
        "num_clients = 5\n",
        "client_data = {f'Client_{i+1}': {'TRAIN_DATA': [], 'TRAIN_LABELS': [], 'TEST_DATA': [], 'TEST_LABELS': []} for i in range(num_clients)}\n",
        "\n",
        "for i in range(num_clients):\n",
        "    start_idx = i * (train_size // num_clients)\n",
        "    end_idx = (i + 1) * (train_size // num_clients)\n",
        "\n",
        "    client_data[f'Client_{i+1}']['TRAIN_DATA'] = np.concatenate((zero_train[start_idx:end_idx], one_train[start_idx:end_idx]))\n",
        "    client_data[f'Client_{i+1}']['TRAIN_LABELS'] = np.array([class_to_label['A']] * (end_idx - start_idx) + [class_to_label['B']] * (end_idx - start_idx))\n",
        "\n",
        "    start_idx = i * (test_size // num_clients)\n",
        "    end_idx = (i + 1) * (test_size // num_clients)\n",
        "\n",
        "    client_data[f'Client_{i+1}']['TEST_DATA'] = np.concatenate((zero_test[start_idx:end_idx], one_test[start_idx:end_idx]))\n",
        "    client_data[f'Client_{i+1}']['TEST_LABELS'] = np.array([class_to_label['A']] * (end_idx - start_idx) + [class_to_label['B']] * (end_idx - start_idx))\n",
        "\n",
        "# Print client data\n",
        "for client, data in client_data.items():\n",
        "    print(f'{client}:')\n",
        "    print(data)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9OweMfaR_E3C"
      },
      "outputs": [],
      "source": [
        "from qiskit.circuit.library import ZFeatureMap, TwoLocal, RealAmplitudes\n",
        "\n",
        "#Define Variational circuit\n",
        "num_qubits = 2\n",
        "\n",
        "# Define the feature map and variational form\n",
        "FEATURE_MAP = ZFeatureMap(feature_dimension=2, reps=2)\n",
        "VAR_FORM = RealAmplitudes(num_qubits, entanglement='full', reps=3)\n",
        "\n",
        "class localOptimizerLog:\n",
        "    \"\"\"Log to store optimizer's intermediate results\"\"\"\n",
        "    def __init__(self):\n",
        "        self.evaluations = []\n",
        "        self.parameters = []\n",
        "        self.costs = []\n",
        "    def update(self, evaluation, parameter, cost, _stepsize, _accept):\n",
        "        \"\"\"Save intermediate results. Optimizer passes five values\n",
        "        but we ignore the last two. evaluation\n",
        "        could represent the value of the objective function\n",
        "        (to be minimized or maximized) or a performance metric (to be optimized). \"\"\"\n",
        "\n",
        "        self.evaluations.append(evaluation)\n",
        "        self.parameters.append(parameter)\n",
        "        self.costs.append(cost)\n",
        "\n",
        "initial_point = np.random.random(VAR_FORM.num_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKOIdXmoAlNJ",
        "outputId": "3c0d5eb9-41fb-4a2d-ae91-be52bd14bd87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-d794646cea55>:18: DeprecationWarning: The quantum_instance argument is deprecated as of version 0.5.0 and will be removed no sooner than 3 months after the release. Instead use the sampler argument.\n",
            "  global_model = VQC(\n"
          ]
        }
      ],
      "source": [
        "#Global optimizer log\n",
        "class GlobalOptimizerLog:\n",
        "    \"\"\"Log to store optimizer's intermediate results\"\"\"\n",
        "    def __init__(self):\n",
        "        self.evaluations = []\n",
        "        self.parameters = []\n",
        "        self.costs = []\n",
        "    def update(self, evaluation, parameter, cost, _stepsize, _accept):\n",
        "        \"\"\"Save intermediate results. Optimizer passes five values\n",
        "        but we ignore the last two.\"\"\"\n",
        "        self.evaluations.append(evaluation)\n",
        "        self.parameters.append(parameter)\n",
        "        self.costs.append(cost)\n",
        "\n",
        "global_optimizer_log = GlobalOptimizerLog()\n",
        "\n",
        "# Initialize global model\n",
        "global_model = VQC(\n",
        "    feature_map=FEATURE_MAP,\n",
        "    ansatz=VAR_FORM,\n",
        "    loss='cross_entropy',\n",
        "    optimizer=SPSA(callback=global_optimizer_log.update),\n",
        "    initial_point=initial_point,\n",
        "    quantum_instance=BasicAer.get_backend('qasm_simulator')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HGjxJb3NoiTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87dfc1cc-1101-4f92-8486-58618ea8cf98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCtCHZ0feMb7"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# Define a function to create a deep unfolded quantum circuit\n",
        "def create_deep_unfolded_circuit(feature_map, ansatz, unfolding_depth):\n",
        "    deep_unfolded_circuit = qiskit.QuantumCircuit()\n",
        "    for _ in range(unfolding_depth):\n",
        "        deep_unfolded_circuit += feature_map\n",
        "        deep_unfolded_circuit += ansatz\n",
        "    return deep_unfolded_circuit\n",
        "# Create a list of clients\n",
        "#clients = [syft.VirtualMachine() for _ in range(num_clients)]\n",
        "\n",
        "# Define client-specific data and deep unfolded quantum circuits\n",
        "client_data = [np.random.rand(100, 3) for _ in range(num_clients)]\n",
        "client_models = [create_deep_unfolded_circuit(quantum_feature_map, quantum_ansatz, unfolding_depth) for _ in range(num_clients)]\n",
        "\n",
        "# Initialize a global model\n",
        "global_model = create_deep_unfolded_circuit(quantum_feature_map, quantum_ansatz, unfolding_depth)\n",
        "\n",
        "# Federated Learning Loop\n",
        "num_iterations = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    global_model_params = global_model.get_parameters()\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        # Train client models on local data\n",
        "        local_data = client_data[i]\n",
        "        local_model = client_models[i]\n",
        "\n",
        "        # Perform optimization on the local model with client-specific data\n",
        "        # This step involves running the quantum circuit and adjusting parameters\n",
        "        local_optimizer = qiskit.optimizers.COBYLA(maxiter=100)\n",
        "        local_optimizer.optimize(local_model, local_data)\n",
        "\n",
        "        # Share the updated local model parameters with the global server\n",
        "        local_model_params = local_model.get_parameters()\n",
        "        global_model_params += (learning_rate * (local_model_params - global_model_params))\n",
        "\n",
        "    # Update the global model with federated averaging\n",
        "    global_model.update_parameters(global_model_params)\n",
        "\n",
        "# Evaluate the global model on a validation or test dataset\n",
        "validation_data = np.random.rand(100, 3)\n",
        "global_model.run(validation_data)\n",
        "'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KWiSrhYE_jvm"
      },
      "outputs": [],
      "source": [
        "#Federated Training\n",
        "from qiskit.algorithms.optimizers import SLSQP\n",
        "#Local Training with Global Training\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Training settings\n",
        "num_rounds = 10\n",
        "learning_rate = 0.001  # Adjust as needed\n",
        "\n",
        "# Create a list of VQC instances, one for each client\n",
        "clients = []\n",
        "# Initialize an empty list to store client logs\n",
        "client_logs = []\n",
        "# Initialize an empty list to store client parameters\n",
        "client_parameters = []\n",
        "global_parameters=[]\n",
        "global_cost=[]\n",
        "\n",
        "# Array to store global cost\n",
        "GlobalCostperRoundAll=[]\n",
        "\n",
        "# Initialize global parameters\n",
        "global_parameters = np.random.rand(VAR_FORM.num_parameters)  # Initialize with random values or any desired initial values\n",
        "#client_weights=learnedweightsR[node][-1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9IxLidBXNWm"
      },
      "outputs": [],
      "source": [
        "\n",
        "trained_params_list = []\n",
        "#trained_params =\n",
        "\n",
        "#trained_params_list.append(trained_params)\n",
        "initial_params = np.random.rand(VAR_FORM.num_parameters)\n",
        "\n",
        "# Main training loop\n",
        "#def train_vqc_with_deep_unfolding(num_layers, num_iterations):\n",
        "\n",
        "    #trained_params = deep_unfolding_vqc(initial_params, num_layers, num_iterations)\n",
        "    #return trained_params\n",
        "params=initial_params\n",
        "\n",
        "# Define the deep unfolding model\n",
        "def deep_unfolding_vqc(params, num_layers, num_iterations):\n",
        "    for layer in range(num_layers):\n",
        "        # Apply one layer of the deep unfolding model\n",
        "        print(\"Layer\", layer)\n",
        "        train_one_layer(params, num_iterations)\n",
        "\n",
        "    #return params #Aggregated parameters return\n",
        "\n",
        "# Define the training process for one layer,\n",
        "#train each client's vqc model and generate global parameter and the parameters of one layer then trnafer to the next layer of deep unfols\n",
        "\n",
        "def train_one_layer(params, num_iterations): #first give random parmeters and then every layer get aggregated parameters\n",
        "    # Define  training process for one layer of the deep unfolding model\n",
        "\n",
        "    # Train VQC for each client and obtain trained parameters\n",
        "    #aggregated_params = np.zeros_like(global_parameters)  # Initialize aggregated parameters\n",
        "    global_parameters = params\n",
        "    #np.random.rand(VAR_FORM.num_parameters)  # need to assign previous layer's global parameters\n",
        "    # Initialize with random values or any desired initial values\n",
        "    aggregated_params=[]\n",
        "    global_cost=[]\n",
        "    client_logs=[]\n",
        "\n",
        "    # Initialize a dictionary to store the sum of parameters for each client for all iterations\n",
        "    #client_parameter_sums = {}\n",
        "\n",
        "    # Federated training loop\n",
        "    for round_num in range(num_iterations):\n",
        "        aggregated_params = np.zeros_like(global_parameters)  # Initialize aggregated parameters\n",
        "        #Initialize aggregated parameters to global result of previous round\n",
        "        # Initialize global parameters\n",
        "        print(\"round Number\", round_num)\n",
        "        # Train each client's data on their VQC models\n",
        "        i=0\n",
        "        i_max=num_clients\n",
        "        for client_id, data in client_data.items():\n",
        "          if i!=i_max+1:\n",
        "            #print(client_id)\n",
        "            train_data = data['TRAIN_DATA']\n",
        "            train_labels = data['TRAIN_LABELS']\n",
        "            test_data = data['TEST_DATA']\n",
        "            test_labels = data['TEST_LABELS']\n",
        "            #train_data, train_labels, test_data, test_labels= data\n",
        "            # Initialize a variable to accumulate the sum of parameters for this client\n",
        "            param_sum = 0\n",
        "\n",
        "            # Set up the optimization\n",
        "            Locallog = localOptimizerLog()\n",
        "            optimizer = SPSA(maxiter=100, callback=Locallog.update)\n",
        "            client_vqc = VQC(feature_map=FEATURE_MAP,\n",
        "                  ansatz=VAR_FORM,\n",
        "                  loss='cross_entropy',\n",
        "                  optimizer=SPSA(callback=Locallog.update),\n",
        "                  initial_point=initial_point,\n",
        "                  quantum_instance=BasicAer.get_backend('qasm_simulator'))\n",
        "\n",
        "            client_vqc.fit(train_data, train_labels)\n",
        "            clients.append(client_vqc)\n",
        "            client_logs.append(Locallog)\n",
        "        #print(len(Locallog.parameters[-1])) #12 parameters for each client\n",
        "        #print(client_weights[i])\n",
        "        #Normalize these weights\n",
        "\n",
        "            import tensorflow as tf\n",
        "            print(f\"Round {round_num}, Client {client_id}: parameters = {Locallog.parameters[-1]}\")\n",
        "\n",
        "            param_sum+=np.sum(Locallog.parameters[-1])\n",
        "            # Convert the NumPy array to a TensorFlow tensor\n",
        "            parameters_tf = tf.convert_to_tensor(Locallog.parameters[-1], dtype=tf.float32)\n",
        "\n",
        "        #weighted_aggregated_params_perclient=parameters_tf * client_weights[i]\n",
        "        #print(f\"Round {round_num}, Client {client_id}: parameters = {weighted_aggregated_params_perclient}\")\n",
        "\n",
        "        # Element-wise multiplication of parameters with client weight\n",
        "        #weighted_params = parameters_tf * client_weights[i]\n",
        "\n",
        "        # Aggregate the weighted parameters\n",
        "        #aggregated_params += weighted_params\n",
        "        #aggregated_params = [sum(value) for value in zip(weighted_aggregated_params_perclient)]\n",
        "        #print(aggregated_params)\n",
        "\n",
        "        # Update aggregated_params by adding the client's parameters element-wise\n",
        "       # Update aggregated_params by adding the weighted client parameters element-wise\n",
        "            aggregated_params += parameters_tf\n",
        "            i=i+1\n",
        "            return aggregated_params\n",
        "\n",
        "    # Calculate the sum of weighted aggregated parameters\n",
        "    #aggregated_params /= sum(client_weights)\n",
        "\n",
        "        global_parameters=aggregated_params\n",
        "        print(f\"Round {round_num},global: aggregated_parameters = {global_parameters}\")\n",
        "        # Update the global optimizer log with the aggregated parameters\n",
        "        global_optimizer_log.parameters.append(global_parameters)\n",
        "        global_model.fit(train_data, train_labels)\n",
        "        global_cost = global_optimizer_log.costs\n",
        "        print(f\"Round {round_num},global cost: {global_cost}\")\n",
        "            # Create a list to store the last values of global_cost\n",
        "\n",
        "        last_values = []\n",
        "        filename = \"Cost_DUNQFL.csv\"\n",
        "\n",
        "        # At the end of each round, save the last value of global_cost\n",
        "        last_value = global_cost[-1]\n",
        "        last_values.append(last_value)\n",
        "\n",
        "        with open(filename, 'w', newline='') as csvfile:\n",
        "          writer = csv.writer(csvfile)\n",
        "        #writer.writerow([\"Label\"] + [f\"Data {i+1}\" for i in range(len(data))])  # Write header row\n",
        "          writer.writerow([\"Last Value\"])  # Write a header row\n",
        "          for last_value in last_values:\n",
        "            writer.writerow([last_value])\n",
        "\n",
        "\n",
        "        print(f\"Results saved to {filename}\")\n",
        "\n",
        "deep_unfolding_vqc(global_parameters, num_layers=1, num_iterations=5)\n",
        "\n",
        "'''\n",
        "# Apply deep unfolding to update VQC parameters\n",
        "trained_params =\n",
        "trained_params_list.append(trained_params)\n",
        "\n",
        "global_parameters=trained_params\n",
        "print(f\"Round {round_num},global: trained_parameters = {global_parameters}\")\n",
        "# Update the global optimizer log with the aggregated parameters\n",
        "global_optimizer_log.parameters.append(global_parameters)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 04: Deep unfolding process to define weights"
      ],
      "metadata": {
        "id": "XqbNrw8fQJYk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl6Mb2UCkPvI",
        "outputId": "b87e33dd-ada8-45ef-bb6b-fbb31eb1a1f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer number 0\n",
            "Iteration number 0\n",
            "Client Client_1: parameters = [ 0.70240055 -1.05382142  0.77379375  0.34514115 -0.34469393  0.56353171\n",
            "  1.8775824   1.99467534]\n",
            "Client Client_2: parameters = [ 1.29018301  0.67799568 -0.24702697 -0.11595956  1.35495231 -0.27163683\n",
            "  0.59595867  1.21040985]\n",
            "Client Client_3: parameters = [ 2.13855549 -0.47568943  2.02718159  3.15874921  1.10269465 -1.44438176\n",
            " -0.41714362  1.67244737]\n",
            "Client Client_4: parameters = [ 1.20676955  0.40441808  0.88588582  0.27832984 -0.52001236 -0.34446551\n",
            "  1.4365576   0.68135058]\n",
            "Client Client_5: parameters = [ 1.38387551 -0.01868705  1.02818321  0.33572248  0.13273261 -0.04250996\n",
            "  0.41733108  0.89462469]\n",
            "call train one layer function for layer and received trained parameters per iteration 0\n",
            "Number of elements in trained parameter list 8\n",
            "Iteration: 0 IterAggregatedPara: [ 0.34444339  0.00938137  0.2571419   0.10347259  0.01662521 -0.03408995\n",
            "  0.13914573  0.22213349]\n",
            "Iteration number 1\n",
            "Client Client_1: parameters = [ 2.19907665 -1.26725523 -1.23674118  0.28959604  1.0082662  -0.37085887\n",
            "  1.09092898  1.35922302]\n",
            "Client Client_2: parameters = [ 1.40914306  0.49325833 -0.20496965 -0.07559243  1.04917494 -0.032122\n",
            "  0.77730719 -0.42296071]\n",
            "Client Client_3: parameters = [ 1.1213182   0.23536117  0.29347456 -0.02782319  0.85827498 -0.48711764\n",
            "  0.77084772 -0.48835945]\n"
          ]
        }
      ],
      "source": [
        "################This is the latest modifying code####################\n",
        "#Proxy data for layer optimization\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Combine the data points from both classes\n",
        "combined_data = np.concatenate((zero_datapoints_normalized, one_datapoints_normalized), axis=0)\n",
        "\n",
        "# Combine the labels for both classes\n",
        "combined_labels = np.concatenate((np.zeros(zero_datapoints_normalized.shape[0]), np.ones(one_datapoints_normalized.shape[0])))\n",
        "\n",
        "# Split the combined data and labels into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_data, combined_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "########################################################################\n",
        "#trained_params_list.append(trained_params)\n",
        "\n",
        "\n",
        "# Main training loop\n",
        "#def train_vqc_with_deep_unfolding(num_layers, num_iterations):\n",
        "\n",
        "    #trained_params = deep_unfolding_vqc(initial_params, num_layers, num_iterations)\n",
        "    #return trained_params\n",
        "trained_params_list = []\n",
        "initial_params = np.random.rand(VAR_FORM.num_parameters)\n",
        "#np.zeros_like(global_parameters)  # Initialize aggregated parameters\n",
        "params=initial_params\n",
        "Sum_client_Para_perIteration = []\n",
        "\n",
        "# Define the deep unfolding model\n",
        "def deep_unfolding_vqc(params, num_layers, num_iterations):\n",
        "    # Initialize a dictionary to store the aggregated results\n",
        "    aggregated_params_perIteration = {}\n",
        "\n",
        "    # Initialize a dictionary to store the trained parameters for each client for all iterations\n",
        "    Client_Trained_Params = {}\n",
        "    LayerAggregatedPara=[]\n",
        "    for layer in range(num_layers):\n",
        "        print(\"Layer number\", layer)\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            print(\"Iteration number\", iteration)\n",
        "            Client_Trained_Params=train_one_layer(params,iteration,layer)\n",
        "            print(\"call train one layer function for layer and received trained parameters per iteration\", layer)\n",
        "\n",
        "            #Calculate aggregate parameters at the end of each iteration,\n",
        "            #and assign simple averaged aggregated parameters as the initial values for next iteration for first layer\n",
        "            # Determine the number of elements in each client's list\n",
        "\n",
        "            num_elements = len(next(iter(Client_Trained_Params.values())))\n",
        "            print(\"Number of elements in trained parameter list\", num_elements)\n",
        "            # Iterate through the indices (0, 1, 2, 3, 4)\n",
        "            for index in range(num_elements):\n",
        "            # Initialize the sum for this index\n",
        "                 index_sum = 0\n",
        "\n",
        "                # Iterate through each client and add their value at the current index\n",
        "                 for client, values in Client_Trained_Params.items():\n",
        "                    index_sum += values[index]\n",
        "                    index_sum=index_sum/num_clients\n",
        "\n",
        "                # Store the sum for this index in a list {ite0:value, ite1:value....iten:value}\n",
        "                 aggregated_params_perIteration[index] = index_sum\n",
        "\n",
        "            # Initialize an empty list to store the values from the dictionary\n",
        "            params_list=[]\n",
        "            # Return the final aggregated parameters per iteration\n",
        "            # since `aggregated_params_perIteration` dictionary\n",
        "            for value in aggregated_params_perIteration.values():\n",
        "                params_list = np.append(params_list,value)\n",
        "            params=np.array(params_list)\n",
        "            #params = aggregated_params_perIteration\n",
        "            print(f\"Iteration: {layer} IterAggregatedPara: {params}\")\n",
        "            iteration += 1\n",
        "\n",
        "        if iteration == num_iterations: #at the final iteration in one layer\n",
        "            LayerAggregatedPara=params\n",
        "            print(f\"Layer: {layer} LayerAggregatedPara: {LayerAggregatedPara}\")\n",
        "\n",
        "        #use thses layer parameter to train proxy data in global model prototype and optimize the vqc parameters\n",
        "        #Then assign optimized parmetrs to params to work with next deep unfolding layer.\n",
        "        global_parameters=LayerAggregatedPara\n",
        "        # Initialize global model\n",
        "        global_model = VQC(\n",
        "           feature_map=FEATURE_MAP,\n",
        "           ansatz=VAR_FORM,\n",
        "           loss='cross_entropy',\n",
        "           optimizer=SPSA(callback=global_optimizer_log.update),\n",
        "           initial_point=global_parameters,\n",
        "           quantum_instance=BasicAer.get_backend('qasm_simulator')\n",
        "          )\n",
        "        global_model.fit(X_train, y_train)\n",
        "        global_paralayer= global_optimizer_log.parameters\n",
        "        print(f\"Layer {layer},global parameter: {global_paralayer}\")\n",
        "        params=global_paralayer\n",
        "\n",
        "        #Final process to clauclate client weights after unfolding process.\n",
        "        if layer == num_layers:\n",
        "          # Initialize a list to store the sum of parameters for each client\n",
        "          clients_sums = []\n",
        "          clients_weights=[]\n",
        "\n",
        "          # Iterate through the clients and calculate the sum of parameters for each client\n",
        "          for client, parameters in Client_Trained_Params.items():\n",
        "              sum_of_parameters = sum(parameters)\n",
        "              clients_sums = sum_of_parameters\n",
        "\n",
        "          # Print the sum of parameters for each client\n",
        "          for client, sum_of_parameters in zip(Client_Trained_Params.keys(), clients_sums):\n",
        "              print(f\"{client}: Sum of Parameters = {sum_of_parameters}\")\n",
        "              clients_weights.append(sum_of_parameters/sum(clients_sums))\n",
        "\n",
        "          # Print the weights for each client\n",
        "          print(\"Client weihts after deep unfolding process\",clients_weights)\n",
        "          #for client, weight in zip(clients_weights):\n",
        "              #print(f\"{client}: Weight = {weight}\")\n",
        "\n",
        "\n",
        "          # The clients_sums list contains the sums of parameters for each client\n",
        "          #print(\"Sums of Parameters for All Clients:\", clients_sums)\n",
        "    return clients_weights\n",
        "\n",
        "    # Return the final parameters\n",
        "    #return Client_Trained_Params\n",
        "\n",
        "    #return params #Aggregated parameters return\n",
        "\n",
        "\n",
        "# Define the training process for one layer,\n",
        "#train each client's vqc model and generate global parameter and the parameters of one layer then trnafer to the next layer of deep unfols\n",
        "def train_one_layer(params,iteration,layer):\n",
        "\n",
        "    #first give random parmeters and then every layer assign params as aggregated parameters #(#initial_params = np.random.rand(VAR_FORM.num_parameters), params=initial_params)\n",
        "    aggregated_params = params\n",
        "\n",
        "    # need to assign previous layer's global parameters\n",
        "\n",
        "    global_cost=[]\n",
        "    client_logs=[]\n",
        "\n",
        "    # Initialize a dictionary to store the trained parameters for each client for all iterations\n",
        "    Client_Trained_Params = {} #(client0:[], client1:[]...)\n",
        "\n",
        "    # Federated training loop\n",
        "\n",
        "    # Train each client's data on their VQC models\n",
        "    #print(\"federaed trainning start\")\n",
        "    i=0\n",
        "    i_max=num_clients\n",
        "    #print(\"done2\",client_data.items())\n",
        "    for client_id, data in client_data.items():\n",
        "      #print(\"done3\")\n",
        "      #if i!=i_max+1:\n",
        "            #print(client_id)\n",
        "      output_list = []  # To store model predictions\n",
        "      target_list = []  # To store target values\n",
        "      param_sum = 0\n",
        "\n",
        "      train_data = data['TRAIN_DATA']\n",
        "      train_labels = data['TRAIN_LABELS']\n",
        "      test_data = data['TEST_DATA']\n",
        "      test_labels = data['TEST_LABELS']\n",
        "\n",
        "      # Set up the optimization\n",
        "      Locallog = localOptimizerLog()\n",
        "      optimizer = SPSA(maxiter=100, callback=Locallog.update)\n",
        "      client_vqc = VQC(feature_map=FEATURE_MAP,\n",
        "            ansatz=VAR_FORM,\n",
        "            loss='cross_entropy',\n",
        "            optimizer=SPSA(callback=Locallog.update),\n",
        "            initial_point=params,\n",
        "            quantum_instance=BasicAer.get_backend('qasm_simulator'))\n",
        "\n",
        "      client_vqc.fit(train_data, train_labels)\n",
        "      clients.append(client_vqc)\n",
        "      client_logs.append(Locallog)\n",
        "\n",
        "      # After training, get the model's predictions on a validation set (test_data)\n",
        "      predictions = client_vqc.predict(test_data)\n",
        "      output_list.append(predictions)\n",
        "      target_list.append(test_labels)\n",
        "\n",
        "      import tensorflow as tf\n",
        "      #print(f\"Round {iteration}, Client {client_id}: parameters = {Locallog.parameters[-1]}\")\n",
        "      print(f\"Client {client_id}: parameters = {Locallog.parameters[-1]}\")\n",
        "      parameters=Locallog.parameters[-1]\n",
        "      #save all sum of parameters into a dictionary and get noramlized sum of weights\n",
        "\n",
        "      # Convert the NumPy array to a TensorFlow tensor\n",
        "      #parameters_tf = tf.convert_to_tensor(Locallog.parameters[-1], dtype=tf.float32)\n",
        "      # Append the parameter data to the dictionary\n",
        "      Client_Trained_Params[client_id] = parameters\n",
        "      #aggregated_params += parameters\n",
        "\n",
        "      #i=i+1\n",
        "    return Client_Trained_Params\n",
        "\n",
        "DUNclient_weights=[]\n",
        "DUNclient_weights=deep_unfolding_vqc(params, num_layers=2, num_iterations=2)\n",
        "federated_training(100,DUNclient_weights,\"origin\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Federated training"
      ],
      "metadata": {
        "id": "cxA13JXH6CFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def federated_training(num_iterations, client_weights, option):\n",
        "    aggregated_params = np.zeros_like(global_parameters)  # Initialize aggregated parameters\n",
        "  # Federtaed training loop\n",
        "    for round_num in range(num_iterations):\n",
        "\n",
        "        #Initialize aggregated parameters to global result of previous round\n",
        "        # Initialize global parameters\n",
        "        print(\"round Number\", round_num)\n",
        "        # Train each client's data on their VQC models\n",
        "        i=0\n",
        "        i_max=num_clients\n",
        "        for client_id, data in client_data.items():\n",
        "          if i!=i_max+1:\n",
        "            #print(client_id)\n",
        "            train_data = data['TRAIN_DATA']\n",
        "            train_labels = data['TRAIN_LABELS']\n",
        "            test_data = data['TEST_DATA']\n",
        "            test_labels = data['TEST_LABELS']\n",
        "            #train_data, train_labels, test_data, test_labels= data\n",
        "            # Initialize a variable to accumulate the sum of parameters for this client\n",
        "            param_sum = 0\n",
        "\n",
        "            # Set up the optimization\n",
        "            Locallog = localOptimizerLog()\n",
        "            optimizer = SPSA(maxiter=100, callback=Locallog.update)\n",
        "            client_vqc = VQC(feature_map=FEATURE_MAP,\n",
        "                  ansatz=VAR_FORM,\n",
        "                  loss='cross_entropy',\n",
        "                  optimizer=SPSA(callback=Locallog.update),\n",
        "                  initial_point=aggregated_params,\n",
        "                  quantum_instance=BasicAer.get_backend('qasm_simulator'))\n",
        "\n",
        "            client_vqc.fit(train_data, train_labels)\n",
        "            clients.append(client_vqc)\n",
        "            client_logs.append(Locallog)\n",
        "        #print(len(Locallog.parameters[-1])) #12 parameters for each client\n",
        "        #print(client_weights[i])\n",
        "        #Normalize these weights\n",
        "\n",
        "            import tensorflow as tf\n",
        "            print(f\"Round {round_num}, Client {client_id}: parameters = {Locallog.parameters[-1]}\")\n",
        "\n",
        "            param_sum+=np.sum(Locallog.parameters[-1])\n",
        "            # Convert the NumPy array to a TensorFlow tensor\n",
        "            parameters_tf = tf.convert_to_tensor(Locallog.parameters[-1], dtype=tf.float32)\n",
        "\n",
        "        #weighted_aggregated_params_perclient=parameters_tf * client_weights[i]\n",
        "        #print(f\"Round {round_num}, Client {client_id}: parameters = {weighted_aggregated_params_perclient}\")\n",
        "\n",
        "        # Element-wise multiplication of parameters with client weight\n",
        "        #weighted_params = parameters_tf * client_weights[i]\n",
        "\n",
        "        # Aggregate the weighted parameters\n",
        "        #aggregated_params += weighted_params\n",
        "        #aggregated_params = [sum(value) for value in zip(weighted_aggregated_params_perclient)]\n",
        "        #print(aggregated_params)\n",
        "\n",
        "        # Update aggregated_params by adding the client's parameters element-wise\n",
        "       # Update aggregated_params by adding the weighted client parameters element-wise\n",
        "            if option == \"origin\":\n",
        "              aggregated_params += parameters_tf\n",
        "              i=i+1\n",
        "              return aggregated_params\n",
        "            if option == \"DUN\"\n",
        "              weighted_params = parameters_tf * client_weights[i]\n",
        "              aggregated_params=weighted_params\n",
        "              i=i+1\n",
        "              return aggregated_params\n",
        "\n",
        "    # Calculate the sum of weighted aggregated parameters\n",
        "    #aggregated_params /= sum(client_weights)\n",
        "\n",
        "        global_parameters=aggregated_params\n",
        "        print(f\"Round {round_num},global: aggregated_parameters = {global_parameters}\")\n",
        "        # Update the global optimizer log with the aggregated parameters\n",
        "        global_optimizer_log.parameters.append(global_parameters)\n",
        "        global_model.fit(train_data, train_labels)\n",
        "        global_cost = global_optimizer_log.costs\n",
        "        print(f\"Round {round_num},global cost: {global_cost}\")\n",
        "        print(f\"Accuracy: {global_model.score(test_data, test_labels)}\")\n",
        "        # Create a list to store the last values of global_cost\n",
        "\n",
        "\n",
        "        last_values = []\n",
        "        filename = \"Cost_DUNQFL.csv\"\n",
        "\n",
        "        # At the end of each round, save the last value of global_cost\n",
        "        last_value = global_cost[-1]\n",
        "        last_values.append(last_value)\n",
        "\n",
        "        with open(filename, 'w', newline='') as csvfile:\n",
        "          writer = csv.writer(csvfile)\n",
        "        #writer.writerow([\"Label\"] + [f\"Data {i+1}\" for i in range(len(data))])  # Write header row\n",
        "          writer.writerow([\"Last Value\"])  # Write a header row\n",
        "          for last_value in last_values:\n",
        "            writer.writerow([last_value])\n",
        "\n",
        "\n",
        "        print(f\"Results saved to {filename}\")\n"
      ],
      "metadata": {
        "id": "zlEs7q878nZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "\n",
        "\n",
        "        global_parameters=aggregated_params\n",
        "print(f\"Round {iteration},global: aggregated_parameters = {global_parameters}\")\n",
        "        # Update the global optimizer log with the aggregated parameters\n",
        "global_optimizer_log.parameters.append(global_parameters)\n",
        "global_model.fit(train_data, train_labels)\n",
        "global_cost = global_optimizer_log.costs\n",
        "print(f\"Round {iteration},global cost: {global_cost}\")\n",
        "# Create a list to store the last values of global_cost\n",
        "\n",
        "last_values = []\n",
        "filename = \"Cost_DUNQFL.csv\"\n",
        "\n",
        "# At the end of each round, save the last value of global_cost\n",
        "last_value = global_cost[-1]\n",
        "last_values.append(last_value)\n",
        "\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    #writer.writerow([\"Label\"] + [f\"Data {i+1}\" for i in range(len(data))])  # Write header row\n",
        "    writer.writerow([\"Last Value\"])  # Write a header row\n",
        "    for last_value in last_values:\n",
        "      writer.writerow([last_value])\n",
        "\n",
        "\n",
        "print(f\"Results saved to {filename}\")\n",
        "\n",
        "\n",
        "# Apply deep unfolding to update VQC parameters\n",
        "trained_params =\n",
        "trained_params_list.append(trained_params)\n",
        "\n",
        "global_parameters=trained_params\n",
        "print(f\"Round {round_num},global: trained_parameters = {global_parameters}\")\n",
        "# Update the global optimizer log with the aggregated parameters\n",
        "global_optimizer_log.parameters.append(global_parameters)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "6HiwPi3Q5tKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "AG2pF-nA4-Fx",
        "outputId": "1082747a-326b-44ea-8b01-e0153ff6aa82"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-779969eb58c7>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mtrained_params_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mclient_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclient_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Train a VQC for the client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Set up the optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'items'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "#from qiskit.aqua.components.optimizers import SPSA\n",
        "#from qiskit.aqua.algorithms import VQC\n",
        "#from qiskit.providers.aer import AerSimulator\n",
        "#from qiskit.aqua import QuantumInstance\n",
        "from qiskit import BasicAer\n",
        "\n",
        "# Define your quantum circuit\n",
        "def create_quantum_circuit(params):\n",
        "    # Define your quantum circuit here\n",
        "    n_qubits = 4  # Adjust based on your circuit\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "\n",
        "    # Apply quantum gates based on the parameters\n",
        "    for i in range(n_qubits):\n",
        "        qc.rx(params[i], i)\n",
        "\n",
        "    return qc\n",
        "\n",
        "# Define a function to evaluate the quantum circuit\n",
        "def evaluate_quantum_circuit(params):\n",
        "    # Create the quantum circuit\n",
        "    qc = create_quantum_circuit(params)\n",
        "\n",
        "    # Simulate the circuit\n",
        "    simulator = AerSimulator()\n",
        "    quantum_instance = QuantumInstance(simulator, shots=1024)  # Adjust shots as needed\n",
        "    vqc = VQC(feature_map=FEATURE_MAP, ansatz=VAR_FORM, loss='cross_entropy',\n",
        "              optimizer=SPSA(callback=Locallog.update), initial_point=params,\n",
        "              quantum_instance=quantum_instance)\n",
        "    vqc_circuit = vqc.construct_circuit(params)\n",
        "    job = quantum_instance.execute(vqc_circuit)\n",
        "    result = job.result()\n",
        "\n",
        "    # Extract the output state vector or other relevant information\n",
        "    statevector = result.get_statevector()\n",
        "\n",
        "    return statevector\n",
        "\n",
        "# Define the deep unfolding model\n",
        "def deep_unfolding_vqc(params, num_layers):\n",
        "    for layer in range(num_layers):\n",
        "        # Apply one layer of the deep unfolding model\n",
        "        params = train_one_layer(params)\n",
        "    return params\n",
        "\n",
        "# Define the training process for one layer\n",
        "def train_one_layer(params):\n",
        "    # Define your training process for one layer of the deep unfolding model\n",
        "    # This could involve gradient descent or other optimization techniques\n",
        "    optimizer = SPSA()\n",
        "    # Modify this part to optimize the quantum circuit's parameters\n",
        "    params, _ = optimizer.optimize(num_vars=len(params), objective_function=lambda x: loss_function(x))\n",
        "    return params\n",
        "\n",
        "# Define a loss function\n",
        "def loss_function(params):\n",
        "    # Define your loss function based on the task\n",
        "    # You may need to compare the output of the quantum circuit with ground truth\n",
        "    target_state = np.array([0.0, 1.0, 0.0, 0.0])\n",
        "    quantum_state = evaluate_quantum_circuit(params)\n",
        "    return np.linalg.norm(quantum_state - target_state)  # Example loss\n",
        "\n",
        "# Main training loop for one client\n",
        "def train_vqc_with_deep_unfolding(num_layers, num_iterations):\n",
        "    initial_params = np.random.rand(4)\n",
        "    trained_params = deep_unfolding_vqc(initial_params, num_layers)\n",
        "    return trained_params\n",
        "\n",
        "# List of clients (each client has its own data)\n",
        "#client_data_list = client_data.items\n",
        "\n",
        "# Train VQC and apply deep unfolding for each client\n",
        "trained_params_list = []\n",
        "\n",
        "for client_data in client_data.items():\n",
        "    # Train a VQC for the client\n",
        "    # Set up the optimization\n",
        "    Locallog = localOptimizerLog()\n",
        "    vqc = VQC(feature_map=FEATURE_MAP, ansatz=VAR_FORM, loss='cross_entropy',\n",
        "              optimizer=SPSA(callback=Locallog.update), initial_point=None,\n",
        "              quantum_instance=BasicAer.get_backend('qasm_simulator'))\n",
        "    vqc.fit(train_data, train_labels)\n",
        "\n",
        "    # Apply deep unfolding to update VQC parameters\n",
        "    trained_params = train_vqc_with_deep_unfolding(num_layers=4, num_iterations=10)\n",
        "    trained_params_list.append(trained_params)\n",
        "\n",
        "# Print the trained parameters for each client\n",
        "for client_id, trained_params in enumerate(trained_params_list):\n",
        "    print(f\"Client {client_id + 1} Trained Parameters:\", trained_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "bXwgqle2ihwk",
        "outputId": "585453db-dafc-4c83-8fb3-c89686ba0c12"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-378edd4ae2bc>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mi_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_clients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mclient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclient_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mi_max\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print(client_id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'items'"
          ]
        }
      ],
      "source": [
        "#Weighted FL\n",
        "aggregated_params = np.zeros_like(global_parameters)  # Initialize aggregated parameters\n",
        "\n",
        "# Federated training loop\n",
        "for round_num in range(num_rounds):\n",
        "    global_cost=[]\n",
        "    client_logs=[]\n",
        "\n",
        "    #Initialize aggregated parameters to global result of previous round\n",
        "\n",
        "    # Train each client's data on their VQC models\n",
        "    i=0\n",
        "    i_max=num_clients\n",
        "    for client_id, data in client_data.items():\n",
        "       if i!=i_max+1:\n",
        "        #print(client_id)\n",
        "        train_data = data['TRAIN_DATA']\n",
        "        train_labels = data['TRAIN_LABELS']\n",
        "        test_data = data['TEST_DATA']\n",
        "        test_labels = data['TEST_LABELS']\n",
        "        #train_data, train_labels, test_data, test_labels= data\n",
        "\n",
        "        # Set up the optimization\n",
        "\n",
        "        Locallog = localOptimizerLog()\n",
        "        optimizer = SPSA(maxiter=100, callback=Locallog.update)\n",
        "        vqc = VQC(feature_map=FEATURE_MAP,\n",
        "          ansatz=VAR_FORM,\n",
        "          loss='cross_entropy',\n",
        "          optimizer=SPSA(callback=Locallog.update),\n",
        "          initial_point=global_parameters,\n",
        "          quantum_instance=BasicAer.get_backend('qasm_simulator'))\n",
        "\n",
        "        # clear objective value history\n",
        "        objective_func_vals = []\n",
        "\n",
        "        vqc.fit(train_data, train_labels)\n",
        "        clients.append(vqc)\n",
        "        client_logs.append(Locallog)\n",
        "        #print(len(Locallog.parameters[-1])) #12 parameters for each client\n",
        "        #print(client_weights[i])\n",
        "\n",
        "        #Normalize these weights\n",
        "\n",
        "\n",
        "        import tensorflow as tf\n",
        "        print(f\"Round {round_num}, Client {client_id}: parameters = {Locallog.parameters[-1]}\")\n",
        "        # Convert the NumPy array to a TensorFlow tensor\n",
        "        parameters_tf = tf.convert_to_tensor(Locallog.parameters[-1], dtype=tf.float32)\n",
        "\n",
        "        #weighted_aggregated_params_perclient=parameters_tf * client_weights[i]\n",
        "        #print(f\"Round {round_num}, Client {client_id}: parameters = {weighted_aggregated_params_perclient}\")\n",
        "\n",
        "        # Element-wise multiplication of parameters with client weight\n",
        "        #weighted_params = parameters_tf * client_weights[i]\n",
        "\n",
        "        # Aggregate the weighted parameters\n",
        "        #aggregated_params += weighted_params\n",
        "        #aggregated_params = [sum(value) for value in zip(weighted_aggregated_params_perclient)]\n",
        "        #print(aggregated_params)\n",
        "\n",
        "        # Update aggregated_params by adding the client's parameters element-wise\n",
        "       # Update aggregated_params by adding the weighted client parameters element-wise\n",
        "        weighted_parameters = parameters_tf\n",
        "        aggregated_params += weighted_parameters\n",
        "        i=i+1\n",
        "\n",
        "\n",
        "    # Calculate the sum of weighted aggregated parameters\n",
        "    #aggregated_params /= sum(client_weights)\n",
        "\n",
        "    global_parameters=aggregated_params\n",
        "    print(f\"Round {round_num},global: aggregated_parameters = {global_parameters}\")\n",
        "    # Update the global optimizer log with the aggregated parameters\n",
        "    global_optimizer_log.parameters.append(global_parameters)\n",
        "    global_model.fit(train_data, train_labels)\n",
        "    global_cost = global_optimizer_log.costs\n",
        "    print(f\"Round {round_num},global cost: {global_cost}\")\n",
        "\n",
        "\n",
        "    # Save results to a CSV file\n",
        "\n",
        "    # Create a list to store the last values of global_cost\n",
        "    last_values = []\n",
        "    filename = \"Cost_DUNQFL.csv\"\n",
        "\n",
        "    # At the end of each round, save the last value of global_cost\n",
        "    last_value = global_cost[-1]\n",
        "    last_values.append(last_value)\n",
        "\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  #writer.writerow([\"Label\"] + [f\"Data {i+1}\" for i in range(len(data))])  # Write header row\n",
        "  writer.writerow([\"Last Value\"])  # Write a header row\n",
        "  for last_value in last_values:\n",
        "    writer.writerow([last_value])\n",
        "\n",
        "\n",
        "print(f\"Results saved to {filename}\")\n",
        "    #global_parameters=global_optimizer_log.parameters[-1]\n",
        "#print(global_parameters)\n",
        "#Aggregate client parameters\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWY-hYGnSOt2"
      },
      "outputs": [],
      "source": [
        "#Weighted FL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#%% Definition of Unfolded FL\n",
        "class TrainDUW(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(TrainDUW, self).__init__()\n",
        "        #self.thetak = nn.ParameterList([nn.Parameter(torch.ones(T)*np.sqrt(len(train_datasets[i])/N)) for i in range(K)])\n",
        "        # initial value: N_k/N\n",
        "    def network(self, W1, b1, W2, b2, W3, b3, x):\n",
        "        x = torch.relu(torch.matmul(x,W1.T)+b1.T)\n",
        "        x = torch.relu(torch.matmul(x,W2.T)+b2.T)\n",
        "        x = F.log_softmax(torch.matmul(x,W3.T)+b3.T, dim=1)\n",
        "        return x\n",
        "\n",
        "    def forward(self, aveW1, aveb1, aveW2, aveb2, aveW3, aveb3):\n",
        "        aggregated_params = np.zeros_like(global_parameters)  # Initialize aggregated parameters\n",
        "\n",
        "        # Federated training loop\n",
        "        for round_num in range(num_rounds):\n",
        "            global_cost=[]\n",
        "            client_logs=[]\n",
        "\n",
        "            aggregated_params = global_parameters.copy()\n",
        "            i=0\n",
        "            i_max=num_clients\n",
        "            for client_id, data in client_data.items():\n",
        "              if i!=i_max+1:\n",
        "                train_data = data['TRAIN_DATA']\n",
        "                train_labels = data['TRAIN_LABELS']\n",
        "                test_data = data['TEST_DATA']\n",
        "                test_labels = data['TEST_LABELS']\n",
        "\n",
        "                Locallog = localOptimizerLog()\n",
        "                optimizer = SPSA(maxiter=100, callback=Locallog.update)\n",
        "                vqc = VQC(feature_map=FEATURE_MAP,\n",
        "                ansatz=VAR_FORM,\n",
        "                loss='cross_entropy',\n",
        "                optimizer=SPSA(callback=Locallog.update),\n",
        "                initial_point=global_parameters,\n",
        "                quantum_instance=BasicAer.get_backend('qasm_simulator'))\n",
        "                vqc.fit(train_data, train_labels)\n",
        "                clients.append(vqc)\n",
        "                client_logs.append(Locallog)\n",
        "                import tensorflow as tf\n",
        "                print(f\"Round {round_num}, Client {client_id}: parameters = {Locallog.parameters[-1]}\")\n",
        "\n",
        "                parameters_tf = tf.convert_to_tensor(Locallog.parameters[-1], dtype=tf.float32)\n",
        "                weighted_parameters = parameters_tf\n",
        "                aggregated_params += weighted_parameters\n",
        "                i=i+1\n",
        "\n",
        "            global_parameters=aggregated_params\n",
        "            print(f\"Round {round_num},global: aggregated_parameters = {global_parameters}\")\n",
        "\n",
        "            global_optimizer_log.parameters.append(global_parameters)\n",
        "            global_model.fit(train_data, train_labels)\n",
        "            global_cost = global_optimizer_log.costs\n",
        "            print(f\"Round {round_num},global cost: {global_cost}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vSEV-egDBvN"
      },
      "outputs": [],
      "source": [
        "        #each client cost variations over epochs for whole set code\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5, 4))\n",
        "# Plot cost for each client over rounds\n",
        "epoch = len(client_logs[0].evaluations)\n",
        "for client_id, log in enumerate(client_logs):\n",
        "    plt.plot(range(epoch), log.costs, label=f'Client {client_id + 1}')\n",
        "plt.plot(range(epoch), global_optimizer_log.costs[-100:], label=\"global\", linewidth=2, marker='*')\n",
        "#plt.plot(range(epoch), global_optimizer_log.costs, label='Global Cost')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('QiskitDUN-QFL Cost Evolution for Optimization-Mnist Data')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1VU2w5RCf3o",
        "outputId": "0692ed62-90d8-476e-a2b8-9227d33b8652"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to DUNcost_globallast Round.csv\n"
          ]
        }
      ],
      "source": [
        "filename2=\"DUNcost_globallast Round.csv\"\n",
        "with open(filename2, 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  #writer.writerow([\"Label\"] + [f\"Data {i+1}\" for i in range(len(data))])  # Write header row\n",
        "  writer.writerow([\"Last Value\"])  # Write a header row\n",
        "  for last_value in last_values:\n",
        "    writer.writerow(global_optimizer_log.costs[-100:])\n",
        "\n",
        "\n",
        "print(f\"Results saved to {filename2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vhj1jKvEoTZg"
      },
      "outputs": [],
      "source": [
        "#Weighted FL\n",
        "aggregated_params = np.zeros_like(global_parameters)  # Initialize aggregated parameters\n",
        "\n",
        "# Federated training loop\n",
        "for round_num in range(num_rounds):\n",
        "    global_cost=[]\n",
        "    client_logs=[]\n",
        "\n",
        "    #Initialize aggregated parameters to global result of previous round\n",
        "\n",
        "    # Train each client's data on their VQC models\n",
        "    i=0\n",
        "    i_max=num_clients\n",
        "    for client_id, data in client_data.items():\n",
        "       if i!=i_max+1:\n",
        "        #print(client_id)\n",
        "        train_data = data['TRAIN_DATA']\n",
        "        train_labels = data['TRAIN_LABELS']\n",
        "        test_data = data['TEST_DATA']\n",
        "        test_labels = data['TEST_LABELS']\n",
        "        #train_data, train_labels, test_data, test_labels= data\n",
        "\n",
        "        # Set up the optimization\n",
        "\n",
        "        Locallog = localOptimizerLog()\n",
        "        optimizer = SPSA(maxiter=100, callback=Locallog.update)\n",
        "        vqc = VQC(feature_map=FEATURE_MAP,\n",
        "          ansatz=VAR_FORM,\n",
        "          loss='cross_entropy',\n",
        "          optimizer=SPSA(callback=Locallog.update),\n",
        "          initial_point=global_parameters,\n",
        "          quantum_instance=BasicAer.get_backend('qasm_simulator'))\n",
        "\n",
        "        vqc.fit(train_data, train_labels)\n",
        "        clients.append(vqc)\n",
        "        client_logs.append(Locallog)\n",
        "        #print(len(Locallog.parameters[-1])) #12 parameters for each client\n",
        "        #print(client_weights[i])\n",
        "\n",
        "        #Normalize these weights\n",
        "\n",
        "\n",
        "        import tensorflow as tf\n",
        "        print(f\"Round {round_num}, Client {client_id}: parameters = {Locallog.parameters[-1]}\")\n",
        "        # Convert the NumPy array to a TensorFlow tensor\n",
        "        parameters_tf = tf.convert_to_tensor(Locallog.parameters[-1], dtype=tf.float32)\n",
        "\n",
        "        #weighted_aggregated_params_perclient=parameters_tf * client_weights[i]\n",
        "        #print(f\"Round {round_num}, Client {client_id}: parameters = {weighted_aggregated_params_perclient}\")\n",
        "\n",
        "        # Element-wise multiplication of parameters with client weight\n",
        "        #weighted_params = parameters_tf * client_weights[i]\n",
        "\n",
        "        # Aggregate the weighted parameters\n",
        "        #aggregated_params += weighted_params\n",
        "        #aggregated_params = [sum(value) for value in zip(weighted_aggregated_params_perclient)]\n",
        "        #print(aggregated_params)\n",
        "\n",
        "        # Update aggregated_params by adding the client's parameters element-wise\n",
        "       # Update aggregated_params by adding the weighted client parameters element-wise\n",
        "        weighted_parameters = parameters_tf * client_weights[i]\n",
        "        aggregated_params += weighted_parameters\n",
        "        i=i+1\n",
        "\n",
        "\n",
        "    # Calculate the sum of weighted aggregated parameters\n",
        "    aggregated_params /= sum(client_weights)\n",
        "\n",
        "    global_parameters=aggregated_params\n",
        "    print(f\"Round {round_num},global: aggregated_parameters = {global_parameters}\")\n",
        "    # Update the global optimizer log with the aggregated parameters\n",
        "    global_optimizer_log.parameters.append(global_parameters)\n",
        "    global_model.fit(train_data, train_labels)\n",
        "    global_cost = global_optimizer_log.costs\n",
        "    print(f\"Round {round_num},global cost: {global_cost}\")\n",
        "\n",
        "\n",
        "      # Save results to a CSV file\n",
        "\n",
        "    # Create a list to store the last values of global_cost\n",
        "    last_values = []\n",
        "    filename = \"Cost_DUNQFL.csv\"\n",
        "\n",
        "     # At the end of each round, save the last value of global_cost\n",
        "    last_value = global_cost[-1]\n",
        "    last_values.append(last_value)\n",
        "\n",
        "with open(filename, 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  #writer.writerow([\"Label\"] + [f\"Data {i+1}\" for i in range(len(data))])  # Write header row\n",
        "  writer.writerow([\"Last Value\"])  # Write a header row\n",
        "  for last_value in last_values:\n",
        "    writer.writerow([last_value])\n",
        "\n",
        "\n",
        "print(f\"Results saved to {filename}\")\n",
        "    #global_parameters=global_optimizer_log.parameters[-1]\n",
        "#print(global_parameters)\n",
        "#Aggregate client parameters\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Visualization"
      ],
      "metadata": {
        "id": "NvtHZcWX6PwH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D5zfpmpCs7m"
      },
      "outputs": [],
      "source": [
        "filename2=\"cost_globallast Round.csv\"\n",
        "with open(filename2, 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  #writer.writerow([\"Label\"] + [f\"Data {i+1}\" for i in range(len(data))])  # Write header row\n",
        "  writer.writerow([\"Last Value\"])  # Write a header row\n",
        "  for last_value in last_values:\n",
        "    writer.writerow(global_optimizer_log.costs[-100:])\n",
        "\n",
        "\n",
        "print(f\"Results saved to {filename2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Hl2M5XlFkaQL",
        "outputId": "489af3a8-3f4e-4502-cef4-494ba795d44d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 500x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "# Read data from the CSV file and append it to the list\n",
        "fileName1=\"/content/drive/MyDrive/Colab Notebooks/QFL/cost_globallast Round.csv\"\n",
        "qfl=[]\n",
        "dunqfl=[]\n",
        "try:\n",
        "    with open(fileName1, mode='r', newline='') as csv_file:\n",
        "        reader = csv.reader(csv_file)\n",
        "        next(reader)  # Skip the header row if present\n",
        "        for row in reader:\n",
        "            # Assuming the CSV file has one column\n",
        "            dunqfl.append((float(row[1])))\n",
        "            qfl.append(float(row[0]))  # Convert to float if needed\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file '{fileName1}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "#each client cost variations over epochs for whole set code\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5, 4))\n",
        "# Plot cost for each client over rounds\n",
        "epoch = 100\n",
        "#for client_id, log in enumerate(client_logs):\n",
        "    #plt.plot(range(epoch), log.costs, label=f'Client {client_id + 1}', linestyle='dashed')\n",
        "plt.plot(range(epoch), qfl, label=\"QFL\", linewidth=1,color='orange')#LR=0.01, maxiter=100\n",
        "plt.plot(range(epoch), dunqfl, label=\"DUN_QFL\", linewidth=1,color='blue')#LR=0.01, maxiter=100\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('QFL vs DeepUnfolding WeightQFL', fontsize=10)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1-NIPAPQOAlrsfwVZwTZ4I5BQLwl5yTMF",
      "authorship_tag": "ABX9TyP1tXxpOFpECBIg4gEQg4lz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}