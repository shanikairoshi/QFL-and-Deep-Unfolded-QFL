{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanikairoshi/QFL-with-DUN/blob/main/QiskitVQC_FLNew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WNVBY7zGqDe9"
      },
      "outputs": [],
      "source": [
        "!pip install qiskit\n",
        "!pip install qiskit_machine_learning\n",
        "# installing TensorFLow Version 2.3.1\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "LQPn06D0qX3u",
        "outputId": "9b9bafb1-2b3c-4707-ef78-fbb489bcbe5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ┌───┐┌─────────────┐                                          ┌───┐»\n",
              "   q_0: ┤ H ├┤ P(2.0*x[0]) ├──■────────────────────────────────────■──┤ H ├»\n",
              "        ├───┤├─────────────┤┌─┴─┐┌──────────────────────────────┐┌─┴─┐├───┤»\n",
              "   q_1: ┤ H ├┤ P(2.0*x[1]) ├┤ X ├┤ P(2.0*(π - x[0])*(π - x[1])) ├┤ X ├┤ H ├»\n",
              "        └───┘└─────────────┘└───┘└──────────────────────────────┘└───┘└───┘»\n",
              "meas: 2/═══════════════════════════════════════════════════════════════════»\n",
              "                                                                           »\n",
              "«        ┌─────────────┐                                          ┌──────────┐»\n",
              "«   q_0: ┤ P(2.0*x[0]) ├──■────────────────────────────────────■──┤ Ry(θ[0]) ├»\n",
              "«        ├─────────────┤┌─┴─┐┌──────────────────────────────┐┌─┴─┐├──────────┤»\n",
              "«   q_1: ┤ P(2.0*x[1]) ├┤ X ├┤ P(2.0*(π - x[0])*(π - x[1])) ├┤ X ├┤ Ry(θ[1]) ├»\n",
              "«        └─────────────┘└───┘└──────────────────────────────┘└───┘└──────────┘»\n",
              "«meas: 2/═════════════════════════════════════════════════════════════════════»\n",
              "«                                                                             »\n",
              "«        ┌──────────┐   ┌──────────┐┌──────────┐   ┌──────────┐┌───────────┐ ░ »\n",
              "«   q_0: ┤ Rz(θ[2]) ├─■─┤ Ry(θ[4]) ├┤ Rz(θ[6]) ├─■─┤ Ry(θ[8]) ├┤ Rz(θ[10]) ├─░─»\n",
              "«        ├──────────┤ │ ├──────────┤├──────────┤ │ ├──────────┤├───────────┤ ░ »\n",
              "«   q_1: ┤ Rz(θ[3]) ├─■─┤ Ry(θ[5]) ├┤ Rz(θ[7]) ├─■─┤ Ry(θ[9]) ├┤ Rz(θ[11]) ├─░─»\n",
              "«        └──────────┘   └──────────┘└──────────┘   └──────────┘└───────────┘ ░ »\n",
              "«meas: 2/══════════════════════════════════════════════════════════════════════»\n",
              "«                                                                              »\n",
              "«        ┌─┐   \n",
              "«   q_0: ┤M├───\n",
              "«        └╥┘┌─┐\n",
              "«   q_1: ─╫─┤M├\n",
              "«         ║ └╥┘\n",
              "«meas: 2/═╩══╩═\n",
              "«         0  1 "
            ],
            "text/html": [
              "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐┌─────────────┐                                          ┌───┐»\n",
              "   q_0: ┤ H ├┤ P(2.0*x[0]) ├──■────────────────────────────────────■──┤ H ├»\n",
              "        ├───┤├─────────────┤┌─┴─┐┌──────────────────────────────┐┌─┴─┐├───┤»\n",
              "   q_1: ┤ H ├┤ P(2.0*x[1]) ├┤ X ├┤ P(2.0*(π - x[0])*(π - x[1])) ├┤ X ├┤ H ├»\n",
              "        └───┘└─────────────┘└───┘└──────────────────────────────┘└───┘└───┘»\n",
              "meas: 2/═══════════════════════════════════════════════════════════════════»\n",
              "                                                                           »\n",
              "«        ┌─────────────┐                                          ┌──────────┐»\n",
              "«   q_0: ┤ P(2.0*x[0]) ├──■────────────────────────────────────■──┤ Ry(θ[0]) ├»\n",
              "«        ├─────────────┤┌─┴─┐┌──────────────────────────────┐┌─┴─┐├──────────┤»\n",
              "«   q_1: ┤ P(2.0*x[1]) ├┤ X ├┤ P(2.0*(π - x[0])*(π - x[1])) ├┤ X ├┤ Ry(θ[1]) ├»\n",
              "«        └─────────────┘└───┘└──────────────────────────────┘└───┘└──────────┘»\n",
              "«meas: 2/═════════════════════════════════════════════════════════════════════»\n",
              "«                                                                             »\n",
              "«        ┌──────────┐   ┌──────────┐┌──────────┐   ┌──────────┐┌───────────┐ ░ »\n",
              "«   q_0: ┤ Rz(θ[2]) ├─■─┤ Ry(θ[4]) ├┤ Rz(θ[6]) ├─■─┤ Ry(θ[8]) ├┤ Rz(θ[10]) ├─░─»\n",
              "«        ├──────────┤ │ ├──────────┤├──────────┤ │ ├──────────┤├───────────┤ ░ »\n",
              "«   q_1: ┤ Rz(θ[3]) ├─■─┤ Ry(θ[5]) ├┤ Rz(θ[7]) ├─■─┤ Ry(θ[9]) ├┤ Rz(θ[11]) ├─░─»\n",
              "«        └──────────┘   └──────────┘└──────────┘   └──────────┘└───────────┘ ░ »\n",
              "«meas: 2/══════════════════════════════════════════════════════════════════════»\n",
              "«                                                                              »\n",
              "«        ┌─┐   \n",
              "«   q_0: ┤M├───\n",
              "«        └╥┘┌─┐\n",
              "«   q_1: ─╫─┤M├\n",
              "«         ║ └╥┘\n",
              "«meas: 2/═╩══╩═\n",
              "«         0  1 </pre>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#Split data among clients\n",
        "from qiskit.utils import algorithm_globals\n",
        "algorithm_globals.random_seed = 3142\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(algorithm_globals.random_seed)\n",
        "\n",
        "from qiskit.utils import algorithm_globals\n",
        "import numpy as np\n",
        "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
        "from qiskit_machine_learning.datasets import ad_hoc_data\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "#from qiskit_machine_learning.optimizers import SPSA\n",
        "from qiskit import BasicAer\n",
        "from qiskit import BasicAer, execute\n",
        "from qiskit.algorithms.optimizers import SPSA\n",
        "\n",
        "#from DUNWeightingFramework import *\n",
        "#This is to get client weights which get by classical learning - preprocess.\n",
        "\n",
        "# Set random seed\n",
        "algorithm_globals.random_seed = 3142\n",
        "np.random.seed(algorithm_globals.random_seed)\n",
        "\n",
        "# Define the feature map and variational form\n",
        "FEATURE_MAP = ZZFeatureMap(feature_dimension=2, reps=2)\n",
        "VAR_FORM = TwoLocal(2, ['ry', 'rz'], 'cz', reps=2)\n",
        "\n",
        "# Combine feature map and variational form to create the circuit\n",
        "AD_HOC_CIRCUIT = FEATURE_MAP.compose(VAR_FORM)\n",
        "AD_HOC_CIRCUIT.measure_all()\n",
        "AD_HOC_CIRCUIT.decompose().draw()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "juuiZ3dhyV0N"
      },
      "outputs": [],
      "source": [
        "def circuit_instance(data, variational):\n",
        "    \"\"\"Assigns parameter values to `AD_HOC_CIRCUIT`.\n",
        "    Args:\n",
        "        data (list): Data values for the feature map\n",
        "        variational (list): Parameter values for `VAR_FORM`\n",
        "    Returns:\n",
        "        QuantumCircuit: `AD_HOC_CIRCUIT` with parameters assigned\n",
        "    \"\"\"\n",
        "    parameters = {}\n",
        "    for i, p in enumerate(FEATURE_MAP.ordered_parameters):\n",
        "        parameters[p] = data[i]\n",
        "    for i, p in enumerate(VAR_FORM.ordered_parameters):\n",
        "        parameters[p] = variational[i]\n",
        "    return AD_HOC_CIRCUIT.assign_parameters(parameters)\n",
        "\n",
        "\n",
        "def parity(bitstring):\n",
        "    \"\"\"Returns 1 if parity of `bitstring` is even, otherwise 0.\"\"\"\n",
        "    hamming_weight = sum(int(k) for k in list(bitstring))\n",
        "    return (hamming_weight+1) % 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H1AP9TljstbX"
      },
      "outputs": [],
      "source": [
        "def label_probability(results):\n",
        "    \"\"\"Converts a dict of bitstrings and their counts,\n",
        "    to parities and their counts\"\"\"\n",
        "    shots = sum(results.values())\n",
        "    probabilities = {0: 0, 1: 0}\n",
        "    for bitstring, counts in results.items():\n",
        "        label = parity(bitstring)\n",
        "        probabilities[label] += counts / shots\n",
        "    return probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UKT3syoexEOd"
      },
      "outputs": [],
      "source": [
        "def classification_probability(data, variational):\n",
        "    \"\"\"Classify data points using given parameters.\n",
        "    Args:\n",
        "        data (list): Set of data points to classify\n",
        "        variational (list): Parameters for `VAR_FORM`\n",
        "    Returns:\n",
        "        list[dict]: Probability of circuit classifying\n",
        "                    each data point as 0 or 1.\n",
        "    \"\"\"\n",
        "    circuits = [circuit_instance(d, variational) for d in data]\n",
        "    backend = BasicAer.get_backend('qasm_simulator')\n",
        "    results = execute(circuits, backend).result()\n",
        "    classification = [\n",
        "        label_probability(results.get_counts(c)) for c in circuits]\n",
        "    return classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KJ_1H54HwtIm"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_loss(classification, expected):\n",
        "    \"\"\"Calculate accuracy of predictions using cross entropy loss.\n",
        "    Args:\n",
        "        classification (dict): Dict where keys are possible classes,\n",
        "                               and values are the probability our\n",
        "                               circuit chooses that class.\n",
        "        expected (int): Correct classification of the data point.\n",
        "\n",
        "    Returns:\n",
        "        float: Cross entropy loss\n",
        "    \"\"\"\n",
        "    p = classification.get(expected)  # Prob. of correct classification\n",
        "    return -np.log(p + 1e-10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8CTjHNRYwxRf"
      },
      "outputs": [],
      "source": [
        "def cost_function(data, labels, variational):\n",
        "    \"\"\"Evaluates performance of our circuit with `variational`\n",
        "    parameters on `data`.\n",
        "\n",
        "    Args:\n",
        "        data (list): List of data points to classify\n",
        "        labels (list): List of correct labels for each data point\n",
        "        variational (list): Parameters to use in circuit\n",
        "\n",
        "    Returns:\n",
        "        float: Cost (metric of performance)\n",
        "    \"\"\"\n",
        "    classifications = classification_probability(data, variational)\n",
        "    cost = 0\n",
        "    for i, classification in enumerate(classifications):\n",
        "        cost += cross_entropy_loss(classification, labels[i])\n",
        "    cost /= len(data)\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aH7jtwv8w2Nl"
      },
      "outputs": [],
      "source": [
        "class OptimizerLog:\n",
        "    \"\"\"Log to store optimizer's intermediate results\"\"\"\n",
        "    def __init__(self):\n",
        "        self.evaluations = []\n",
        "        self.parameters = []\n",
        "        self.costs = []\n",
        "    def update(self, evaluation, parameter, cost, _stepsize, _accept):\n",
        "        \"\"\"Save intermediate results. Optimizer passes five values\n",
        "        but we ignore the last two.\"\"\"\n",
        "        self.evaluations.append(evaluation)\n",
        "        self.parameters.append(parameter)\n",
        "        self.costs.append(cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kFWQmRphxdJa"
      },
      "outputs": [],
      "source": [
        "# Set up the optimization\n",
        "\n",
        "log = OptimizerLog()\n",
        "optimizer = SPSA(maxiter=100, callback=log.update)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GVnnRQBTvwjS"
      },
      "outputs": [],
      "source": [
        "initial_point = np.random.random(VAR_FORM.num_parameters)\n",
        "#initial_point = np.array([0.3200227 , 0.6503638 , 0.55995053,\n",
        "                          #0.96566328, 0.38243769, 0.90403094,\n",
        "                          #0.82271449, 0.26810137, 0.61076489,\n",
        "                          #0.82301609, 0.11789148, 0.29667125])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn3yWT8-y4Dk",
        "outputId": "550e4b0b-81b5-4f70-a9b3-23862375d2e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "VAR_FORM.num_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14nFTRkF3TnA",
        "outputId": "30825cfe-dca8-4a53-8a18-6c13d366cd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.68281176 0.53329356 0.30705829 0.36434382 0.84776268 0.62783059\n",
            " 0.09287432 0.43074988 0.6732609  0.39772681 0.45872596 0.59476781]\n"
          ]
        }
      ],
      "source": [
        "print(initial_point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YkY4-5NFsrTB"
      },
      "outputs": [],
      "source": [
        "# Generate ad hoc data for each client\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def generate_client_data(client_id):\n",
        "    TRAIN_DATA, TRAIN_LABELS, TEST_DATA, TEST_LABELS = (\n",
        "        ad_hoc_data(training_size=20, test_size=5, n=2, gap=0.3, one_hot=False)\n",
        "    )\n",
        "    encoder = OneHotEncoder()\n",
        "    train_labels_oh = encoder.fit_transform(TRAIN_LABELS.reshape(-1, 1)).toarray()\n",
        "    test_labels_oh = encoder.fit_transform(TEST_LABELS.reshape(-1, 1)).toarray()\n",
        "\n",
        "    return TRAIN_DATA, train_labels_oh, TEST_DATA, test_labels_oh\n",
        "\n",
        "# Create a list of client data\n",
        "client_data = [generate_client_data(client_id) for client_id in range(5)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "BHrX_IAhtP6E",
        "outputId": "f8e62d4e-cecd-4c25-cdad-dcfb593ac241"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom qiskit_machine_learning.algorithms.classifiers import VQC\\nlog = OptimizerLog()\\nvqc = VQC(feature_map=FEATURE_MAP,\\n          ansatz=VAR_FORM,\\n          loss='cross_entropy',\\n          optimizer=SPSA(callback=log.update),\\n          initial_point=initial_point,\\n          quantum_instance=BasicAer.get_backend('qasm_simulator'))\\n\\nvqc.fit(TRAIN_DATA, train_labels_oh)\\n\\nfig = plt.figure()\\nplt.plot(log.evaluations, log.costs)\\nplt.xlabel('Steps')\\nplt.ylabel('Cost')\\nplt.show()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "'''\n",
        "def objective_function(variational):\n",
        "    \"\"\"Cost function of circuit parameters on training data.\n",
        "    The optimizer will attempt to minimize this.\"\"\"\n",
        "    return cost_function(TRAIN_DATA, TRAIN_LABELS, variational)\n",
        "\n",
        "# Run the optimization\n",
        "result = optimizer.minimize(objective_function, initial_point)\n",
        "\n",
        "opt_var = result.x\n",
        "opt_value = result.fun\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "plt.plot(log.evaluations, log.costs)\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()\n",
        "'''\n",
        "'''\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "log = OptimizerLog()\n",
        "vqc = VQC(feature_map=FEATURE_MAP,\n",
        "          ansatz=VAR_FORM,\n",
        "          loss='cross_entropy',\n",
        "          optimizer=SPSA(callback=log.update),\n",
        "          initial_point=initial_point,\n",
        "          quantum_instance=BasicAer.get_backend('qasm_simulator'))\n",
        "\n",
        "vqc.fit(TRAIN_DATA, train_labels_oh)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(log.evaluations, log.costs)\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "z2ssODBzzOYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ecc900-6b9b-4d3d-95bb-0178a7ac1afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-7735fb404e7e>:18: DeprecationWarning: The quantum_instance argument is deprecated as of version 0.5.0 and will be removed no sooner than 3 months after the release. Instead use the sampler argument.\n",
            "  global_model = VQC(\n"
          ]
        }
      ],
      "source": [
        "#Global optimizer log\n",
        "class GlobalOptimizerLog:\n",
        "    \"\"\"Log to store optimizer's intermediate results\"\"\"\n",
        "    def __init__(self):\n",
        "        self.evaluations = []\n",
        "        self.parameters = []\n",
        "        self.costs = []\n",
        "    def update(self, evaluation, parameter, cost, _stepsize, _accept):\n",
        "        \"\"\"Save intermediate results. Optimizer passes five values\n",
        "        but we ignore the last two.\"\"\"\n",
        "        self.evaluations.append(evaluation)\n",
        "        self.parameters.append(parameter)\n",
        "        self.costs.append(cost)\n",
        "\n",
        "global_optimizer_log = GlobalOptimizerLog()\n",
        "\n",
        "# Initialize global model\n",
        "global_model = VQC(\n",
        "    feature_map=FEATURE_MAP,\n",
        "    ansatz=VAR_FORM,\n",
        "    loss='cross_entropy',\n",
        "    optimizer=SPSA(callback=global_optimizer_log.update),\n",
        "    initial_point=initial_point,\n",
        "    quantum_instance=BasicAer.get_backend('qasm_simulator')\n",
        ")\n",
        "\n",
        "#globallog=GlobalOptimizerLog()\n",
        "\n",
        "\n",
        "# Initialize global model parameters\n",
        "#global_optimizer_log.parameters = np.zeros_like(global_parameters)\n",
        "#global_parameters = np.zeros_like(global_optimizer_log.parameters)\n",
        "\n",
        "#print(globallog.parameters)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UiVcp-oaWKWT"
      },
      "outputs": [],
      "source": [
        "# Training settings\n",
        "num_rounds = 5\n",
        "learning_rate = 0.01  # Adjust as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "ShXaqWFttM5j",
        "outputId": "565fa325-58b9-4ce6-a049-307427cebff8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3b7cf1063712>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m           quantum_instance=BasicAer.get_backend('qasm_simulator'))\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m           \u001b[0mvqc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m           \u001b[0mclients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvqc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_machine_learning/algorithms/trainable_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_machine_learning/algorithms/classifiers/vqc.py\u001b[0m in \u001b[0;36m_fit_internal\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfunction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_interpret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_machine_learning/algorithms/trainable_model.py\u001b[0m in \u001b[0;36m_minimize\u001b[0;34m(self, function)\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[1;32m    294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             optimizer_result = self._optimizer.minimize(\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_point\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit/algorithms/optimizers/spsa.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, fun, x0, jac, bounds)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m# this happens only here because for the calibration the loss function is required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturbation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mget_eta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_eps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals_grouped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_evals_grouped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             get_eta, get_eps = _validate_pert_and_learningrate(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit/algorithms/optimizers/spsa.py\u001b[0m in \u001b[0;36mcalibrate\u001b[0;34m(loss, initial_point, c, stability_constant, target_magnitude, alpha, gamma, modelspace, max_evals_grouped)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mpoints\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minitial_point\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_point\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpert\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_batch_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals_grouped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mavg_magnitudes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit/algorithms/optimizers/spsa.py\u001b[0m in \u001b[0;36m_batch_evaluate\u001b[0;34m(function, points, max_evals_grouped, unpack_points)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_evals_grouped\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_evals_grouped\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;31m# support functions with multiple arguments where the points are given in a tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         return [\n\u001b[0m\u001b[1;32m    729\u001b[0m             \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit/algorithms/optimizers/spsa.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;31m# support functions with multiple arguments where the points are given in a tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         return [\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m         ]\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_machine_learning/algorithms/objective_functions.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# probabilities is of shape (N, num_outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neural_network_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;31m# float(...) is for mypy compliance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_machine_learning/algorithms/objective_functions.py\u001b[0m in \u001b[0;36m_neural_network_forward\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    100\u001b[0m         ):\n\u001b[1;32m    101\u001b[0m             \u001b[0;31m# compute forward and cache the results for re-use in backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;31m# a copy avoids keeping a reference to the same array, so we are sure we have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# different arrays on the next iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_machine_learning/neural_networks/neural_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \"\"\"\n\u001b[1;32m    224\u001b[0m         \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mweights_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_forward_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_machine_learning/neural_networks/neural_network.py\u001b[0m in \u001b[0;36m_validate_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mweights_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweights_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     def _validate_forward_output(\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (12,)"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create a list of VQC instances, one for each client\n",
        "clients = []\n",
        "# Initialize an empty list to store client logs\n",
        "client_logs = []\n",
        "# Initialize an empty list to store client parameters\n",
        "client_parameters = []\n",
        "\n",
        "global_parameters=[]\n",
        "global_cost=[]\n",
        "\n",
        "# Federated training loop\n",
        "for round_num in range(num_rounds):\n",
        "     #client_parameters=global_optimizer_log.parameters[-1]\n",
        "     #print('Round',round_num,'',global_optimizer_log.parameters)\n",
        "     #print(f\"Round {round_num}: global parameters {global_optimizer_log.parameters[-1]}\")\n",
        "    # Aggregate optimizer logs and compute mean gradient\n",
        "     aggregated_params = []  # List to store aggregated parameters for this round\n",
        "\n",
        "     #Train each clients data on each vqc to generate client models\n",
        "     for client_id, data in enumerate(client_data):\n",
        "          #client_parameters=global_optimizer_log.parameters\n",
        "          train_data, train_labels, _, _ = data\n",
        "\n",
        "          log = OptimizerLog()\n",
        "          #set initial points to the global parameters to fine tune the clients on top of global model\n",
        "          vqc = VQC(feature_map=FEATURE_MAP,\n",
        "          ansatz=VAR_FORM,\n",
        "          loss='cross_entropy',\n",
        "          optimizer=SPSA(callback=log.update),\n",
        "          initial_point=global_parameters,\n",
        "          quantum_instance=BasicAer.get_backend('qasm_simulator'))\n",
        "\n",
        "          vqc.fit(train_data, train_labels)\n",
        "\n",
        "          clients.append(vqc)\n",
        "          client_logs.append(log)\n",
        "          client_parameters.append(log.parameters[-1])\n",
        "          cost = log.costs[-1]\n",
        "          print(f\"Round {round_num}, Client {client_id}: parameters = {log.parameters[-1]}\")\n",
        "          #print(f\"Round {round_num}, Client {client_id}: Cost = {cost}\")\n",
        "\n",
        "          aggregated_params.append(client_parameters[client_id])  # Store client's updated parameters\n",
        "\n",
        "        # Print the cost for each client in each round\n",
        "         # Aggregation step\n",
        "     aggregated_params = np.mean(aggregated_params, axis=0)  # Calculate mean of parameters\n",
        "\n",
        "     # Update global parameters for the next round\n",
        "     global_parameters = aggregated_params\n",
        "     # Aggregate client parameters\n",
        "     print(f\"Round {round_num},global: aggregated_gradients = {global_parameters}\")\n",
        "\n",
        "     # Update the global optimizer log with the aggregated parameters\n",
        "     global_optimizer_log.parameters.append(global_parameters)\n",
        "     global_model.fit(train_data, train_labels)\n",
        "     global_cost = global_optimizer_log.costs\n",
        "     print(f\"Round {round_num},global cost: {global_cost}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwZt-6E6PCAh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define  existing code here\n",
        "GlobalCostperRound=[]\n",
        "\n",
        "# Initialize global parameters\n",
        "global_parameters = np.random.rand(VAR_FORM.num_parameters)  # Initialize with random values or any desired initial values\n",
        "\n",
        "# Federated training loop\n",
        "for round_num in range(num_rounds):\n",
        "    global_cost=[]\n",
        "    aggregated_params = np.zeros_like(global_parameters)  # Initialize aggregated parameters\n",
        "\n",
        "    # Train each client's data on their VQC models\n",
        "    for client_id, data in enumerate(client_data):\n",
        "        train_data, train_labels, _, _ = data\n",
        "\n",
        "        log = OptimizerLog()\n",
        "\n",
        "        vqc = VQC(\n",
        "            feature_map=FEATURE_MAP,\n",
        "            ansatz=VAR_FORM,\n",
        "            loss='cross_entropy',\n",
        "            optimizer=SPSA(callback=log.update),\n",
        "            initial_point=global_parameters,\n",
        "            quantum_instance=BasicAer.get_backend('qasm_simulator')\n",
        "            #statevector_simulator\n",
        "        )\n",
        "\n",
        "        vqc.fit(train_data, train_labels)\n",
        "\n",
        "        clients.append(vqc)\n",
        "        client_logs.append(log)\n",
        "\n",
        "        # Append the latest parameters to the client_parameters list\n",
        "        client_parameters.append(log.parameters[-1])\n",
        "        cost = log.costs[-1]\n",
        "        #print(f\"Round {round_num}, Client {client_id}: parameters = {log.parameters[-1]}\")\n",
        "\n",
        "        # Add the client's latest parameters to the aggregated_params\n",
        "        aggregated_params += log.parameters[-1]\n",
        "\n",
        "    # Average the aggregated parameters across clients\n",
        "    aggregated_params /= len(client_data)\n",
        "\n",
        "    # Update global parameters for the next round\n",
        "    global_parameters = aggregated_params\n",
        "\n",
        "    # Perform any global updates, e.g., update the global VQC model using global_parameters\n",
        "    #global_vqc.update_params(global_parameters)\n",
        "\n",
        "    # Print aggregated parameters and global updates\n",
        "    print(f\"Round {round_num}, Global parameters: {global_parameters}\")\n",
        "    global_model.fit(train_data, train_labels)\n",
        "    global_cost = global_optimizer_log.costs\n",
        "    print(f\"Round {round_num}, Global Cost: {min(global_cost)}\")\n",
        "\n",
        "    GlobalCostperRound.append(min(global_cost))\n",
        "\n",
        "print(\"======================================\")\n",
        "print(\"Global cost over communication rounds: \")\n",
        "print(GlobalCostperRound)\n",
        "\n",
        "#each client cost variations over epochs\n",
        "import matplotlib.pyplot as plt\n",
        "#epoch = len(global_optimizer_log.evaluations)\n",
        "num_rounds= [i for i in range(5)]\n",
        "plt.plot(num_rounds, GlobalCostperRound)\n",
        "#plt.plot(range(epoch), global_optimizer_log.costs, label='Global Cost')\n",
        "plt.xlabel('Round')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Cost Evolution for global model')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijHL2XwhwH6a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define your existing code here\n",
        "\n",
        "# Initialize global parameters\n",
        "global_parameters = np.random.rand(VAR_FORM.num_parameters)  # Initialize with random values or any desired initial values\n",
        "\n",
        "# Initialize weights for each client\n",
        "client_weights = [0.2256, 0.1910, 0.1922, 0.1921, 0.1990]  # Adjust weights as needed\n",
        "\n",
        "#For each round I need to run DUN code and get the client weights.\n",
        "\n",
        "# Federated training loop\n",
        "for round_num in range(num_rounds):\n",
        "    global_cost=[]\n",
        "    aggregated_params = np.zeros_like(global_parameters)  # Initialize aggregated parameters\n",
        "\n",
        "    # Train each client's data on their VQC models\n",
        "    for client_id, data in enumerate(client_data):\n",
        "        train_data, train_labels, _, _ = data\n",
        "\n",
        "        log = OptimizerLog()\n",
        "\n",
        "        vqc = VQC(\n",
        "            feature_map=FEATURE_MAP,\n",
        "            ansatz=VAR_FORM,\n",
        "            loss='cross_entropy',\n",
        "            optimizer=SPSA(callback=log.update),\n",
        "            initial_point=global_parameters,\n",
        "            quantum_instance=BasicAer.get_backend('qasm_simulator')\n",
        "        )\n",
        "\n",
        "        vqc.fit(train_data, train_labels)\n",
        "\n",
        "        clients.append(vqc)\n",
        "        client_logs.append(log)\n",
        "\n",
        "        # Append the latest parameters to the client_parameters list\n",
        "        client_parameters.append(log.parameters[-1])\n",
        "        cost = log.costs[-1]\n",
        "        #print(f\"Round {round_num}, Client {client_id}: parameters = {log.parameters[-1]}\")\n",
        "\n",
        "        # Add the client's latest parameters to the aggregated_params\n",
        "        aggregated_params += (client_weights[client_id] *log.parameters[-1])\n",
        "        #aggregated_params.append(client_weights[client_id] * client_parameters[client_id])\n",
        "\n",
        "     # Weighted aggregation step\n",
        "    weighted_aggregated_params = np.sum(aggregated_params, axis=0) / np.sum(client_weights)\n",
        "\n",
        "     #aggregated_params = np.mean(aggregated_params, axis=0)  # Calculate mean of parameters\n",
        "\n",
        "     # Update global parameters for the next round\n",
        "    global_parameters = weighted_aggregated_params  # Update global parameters with weighted aggregated values\n",
        "\n",
        "     # Update global parameters for the next round\n",
        "    global_parameters = aggregated_params\n",
        "\n",
        "    # Perform any global updates, e.g., update the global VQC model using global_parameters\n",
        "    #global_vqc.update_params(global_parameters)\n",
        "\n",
        "\n",
        "        # Print aggregated parameters and global updates\n",
        "    #print(f\"Round {round_num}, Global parameters: {global_parameters}\")\n",
        "    global_model.fit(train_data, train_labels)\n",
        "    global_cost = global_optimizer_log.costs\n",
        "    print(f\"Round {round_num}, Global Cost: {global_cost[-1]}\")\n",
        "\n",
        "    GlobalCostperRound.append(min(global_cost))\n",
        "\n",
        "print(\"======================================\")\n",
        "print(\"Global cost over communication rounds: \")\n",
        "print(GlobalCostperRound)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZVHOXt1qMho"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm3TcO0qnV6l"
      },
      "outputs": [],
      "source": [
        "\n",
        "#each client cost variations over epochs\n",
        "import matplotlib.pyplot as plt\n",
        "#epoch = len(global_optimizer_log.evaluations)\n",
        "num_rounds= [i for i in range(50)]\n",
        "plt.plot(num_rounds, GlobalCostperRound)\n",
        "#plt.plot(range(epoch), global_optimizer_log.costs, label='Global Cost')\n",
        "plt.xlabel('Round')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Cost Evolution for global model')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBscLCksCRyb"
      },
      "outputs": [],
      "source": [
        "\n",
        "#each client cost variations over epochs\n",
        "import matplotlib.pyplot as plt\n",
        "# Plot cost for each client over rounds\n",
        "epoch = len(client_logs[0].evaluations)\n",
        "for client_id, log in enumerate(client_logs):\n",
        "    plt.plot(range(epoch), log.costs, label=f'Client {client_id + 1}')\n",
        "#plt.plot(range(epoch), global_optimizer_log.costs, label='Global Cost')\n",
        "plt.xlabel('Round')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Cost Evolution for Each Client')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajOZPul4FsV6"
      },
      "source": [
        "Weighted Aggregation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv-dIO0exXgL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a list of VQC instances, one for each client\n",
        "clients = []\n",
        "# Initialize an empty list to store client logs\n",
        "client_logs = []\n",
        "# Initialize an empty list to store client parameters\n",
        "client_parameters = []\n",
        "\n",
        "global_parameters=[]\n",
        "global_cost=[]\n",
        "\n",
        "# Initialize weights for each client\n",
        "client_weights = [0.2, 0.3, 0.5, 0.4, 0.7]  # Adjust weights as needed\n",
        "\n",
        "# Federated training loop\n",
        "for round_num in range(num_rounds):\n",
        "     #client_parameters=global_optimizer_log.parameters[-1]\n",
        "     #print('Round',round_num,'',global_optimizer_log.parameters)\n",
        "     #print(f\"Round {round_num}: global parameters {global_optimizer_log.parameters[-1]}\")\n",
        "    # Aggregate optimizer logs and compute mean gradient\n",
        "     aggregated_params = []  # List to store aggregated parameters for this round\n",
        "\n",
        "     #Train each clients data on each vqc to generate client models\n",
        "     for client_id, data in enumerate(client_data):\n",
        "          #client_parameters=global_optimizer_log.parameters\n",
        "          train_data, train_labels, _, _ = data\n",
        "\n",
        "          log = OptimizerLog()\n",
        "\n",
        "          vqc = VQC(feature_map=FEATURE_MAP,\n",
        "          ansatz=VAR_FORM,\n",
        "          loss='cross_entropy',\n",
        "          optimizer=SPSA(callback=log.update),\n",
        "          initial_point=global_parameters,\n",
        "          quantum_instance=BasicAer.get_backend('qasm_simulator'))\n",
        "\n",
        "          vqc.fit(train_data, train_labels)\n",
        "\n",
        "          clients.append(vqc)\n",
        "          client_logs.append(log)\n",
        "          client_parameters.append(log.parameters[-1])\n",
        "          cost = log.costs[-1]\n",
        "          print(f\"Round {round_num}, Client {client_id}: parameters = {log.parameters[-1]}\")\n",
        "          print(f\"Round {round_num}, Client {client_id}: Cost = {cost}\")\n",
        "\n",
        "          aggregated_params.append(client_weights[client_id] * client_parameters[client_id])\n",
        "\n",
        "          #aggregated_params.append(client_parameters[client_id])  # Store client's updated parameters\n",
        "\n",
        "        # Print the cost for each client in each round\n",
        "         # Aggregation step\n",
        "     # Weighted aggregation step\n",
        "     weighted_aggregated_params = np.sum(aggregated_params, axis=0) / np.sum(client_weights)\n",
        "\n",
        "     #aggregated_params = np.mean(aggregated_params, axis=0)  # Calculate mean of parameters\n",
        "\n",
        "     # Update global parameters for the next round\n",
        "     global_parameters = weighted_aggregated_params  # Update global parameters with weighted aggregated values\n",
        "\n",
        "     # Update global parameters for the next round\n",
        "     global_parameters = aggregated_params\n",
        "     # Aggregate client parameters\n",
        "     print(f\"Round {round_num},global: aggregated_gradients = {global_parameters}\")\n",
        "\n",
        "     # Update the global optimizer log with the aggregated parameters\n",
        "     global_optimizer_log.parameters.append(global_parameters)\n",
        "     global_model.fit(train_data, train_labels)\n",
        "     global_cost = global_optimizer_log.costs\n",
        "     print(f\"Round {round_num},global cost: {global_cost}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPpQjcvnMNKbR8yYtX09kNi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}